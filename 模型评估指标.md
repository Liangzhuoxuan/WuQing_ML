### 分类模型评估指标



混淆矩阵

| 预测值/真实值 | 1    | 0    |
| :------------ | ---- | ---- |
| 1             | TP   | FP   |
| 0             | FN   | TN   |

**精准率**（查准率） precision：$\frac{TP}{TP+FP}$，表示预测正确的值占预测值的比例

**召回率**（查全率） recall：$\frac{TP}{TP+FN}$，表示预测正确的值占真实值的比例

对比于最平常的评估指标准确率 accurcy

**F1-score**: $\frac{1}{F1} = 2*\frac{precision*recall}{precision+recall}$，是取精准率和召回率的平均



**PR曲线**：

P-R曲线的P就是查准率（Precision），R就是查全率（Recall）。以P作为横坐标，R作为纵坐标，就可以画出P-R曲线。

对于同一个模型，通过调整分类阈值，可以得到不同的P-R值，从而可以得到一条曲线（纵坐标为P，横坐标为R）。通常随着分类阈值从大到小变化（大于阈值认为P），Precision减小，Recall增加。比较两个分类器好坏时，显然是查得又准又全的比较好，也就是的PR曲线越往坐标（1，1）的位置靠近越好。若一个学习器的P-R曲线被另一个学习器完全”包住”，则后者的性能优于前者。当存在交叉时，可以计算曲线围住面积，不太容易判断，但是可以通过平衡点（查准率=查全率，Break-Even  Point，BEP）来判断。

*P-R绘制的原理*：

对于每一个样本，分类器都可以获得一个分类的 为1的概率，当 Probability > threshold 的时候才会分类为正样本，而 P-R 曲线绘制的过程，就是将这个阈值从1遍历到0，对于每一个阈值，划分出正负样本的数量，并计算精准率和召回率确定一个点，绘制曲线





**ROC曲线和AUC：**

AUC（Area Under the ROC Curve）指标是在二分类问题中，模型评估阶段常被用作最重要的评估指标来衡量模型的稳定性。

根据混淆矩阵，我们可以得到另外两个指标：

真正例率，True Positive Rate：TPR = TP/ (TP+TN)，表示预测正确占总正样本的比例

假正例率， False Postive Rate：FPR = FP/(TN+FP)，预测错误的占总负样本的比例


*ROC曲线绘制原理：*
对分类的概率进行排序，依次遍历其中这些概率，大于这个概率的样本为正样本，小于的为负样本，计算 TPR 和FPR 进行绘图

以真正例率（TPR）作为纵轴，以假正例率（FPR）作为横轴作图，便得到了ROC曲线，ROC曲线的面积越大，证明分类效果越好，如果越接近于 $y = -x$ 这条直线，证明分类效果越差，模型拟合得越差。



### 回归模型评估指标



**MSE**(Mean Squared Error) 均方误差，

**MAE**(Mean Absolute Error) 平均绝对误差，

**MAE** 平方绝对误差



MSE 和 RMSE 可以很好的反应回归模型预测值和真实值的偏离程度，但是如果个别离群点的偏离程度很大，即使数量很少，但是也会使得RMSE变得很差（因为还平方了）解决这种问题的方法：

1. 数据预处理是过滤掉异常点
2. 不是异常点的话尽量加进去，提升模型的鲁棒性
3. 可以使用鲁棒性更好的评价指标 MAE



### 推荐系统里的评估指标

**余弦相似度**

**优缺点**

==我们知道余弦相似度关注的是两个向量之间的角度关系，并不关心其绝对大小。==在推荐系统的最直接的优点在于：不同用户对电影的打分力度不同，有的严一点平均打分低，有的松一点平均打分都很高，用余弦相似性可以排除打分程度的干扰，关注相对差异。

总的来说欧式距离体现的数值上的绝对差异，而余弦距离体现方向上的相对差异。