<img src="https://mmbiz.qpic.cn/mmbiz_png/jA1wO8icw0gAr0N9oRvm5xELDAJZu1eJUdxhhHFgBiaAFrU0V4WvzLNU3nzVTmcvCTY88Z9kaC8MlTteIe8I5Cwg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img" style="zoom: 50%;" />





数据清洗的一般流程：

- Step 1：

  格式内容清洗；

- Step 2：

  逻辑错误清洗；

- Step 3：

  异常数据清洗；

- Step 4：

  缺失数据清洗；

- Step 5：

  非需求数据清洗。



### 1.0 格式内容清洗

#### 1.1 格式内容问题产生的原因

- 从不同的数据源收集来的
- 人工收集或用户填写等会不一致

#### 1.2 时间、日期格式不一致清洗（不统一）

根据实际情况，把时间，日期的格式进行统一

如：

- 日期格式不一致
- 时间戳单位不一致，如秒，分的不同单位
- 使用无效时间表示，时间戳使用0表示，结束时间戳使用FFFF表示

#### 1.3 数值格式不一致清洗（不统一）

根据实际情况，对格式进行统一

如4，四，4.001344

#### 1.4 全半角等显示格式不一致清洗

这个问题在人工录入数据时比较容易出现。

#### 1.5 内容中有不该存在的字符清洗（多了）

如中国人的姓名中出现英文字母，身份证号里面出现汉子等问题

#### 1.6 内容与该字段应有内容不符清洗（错了）

姓名写了性别，身份证号写了手机号等等，均属这种问题。但该问题特殊性在于：并不能简单的以删除来处理，因为成因有可能是人工填写错误，也有可能是前端没有校验，还有可能是导入数据时部分或全部存在列没有对齐的问题，因此要详细识别问题类型。

#### 1.7 数据类型不符清洗

进行类型转换

### 2.0 逻辑错误清洗

#### 2.1 数据重复清洗

> df.drop_duplicates()

1. 存在相同的特征值，存在完全相同的多个样本
2. 数据不完全相同，但是从业务角度看是同一个数据

#### 2.2 不合理清洗

异常值的，不对头的，可以话**箱型图**

不合理值的例子：

- 年龄：

  200岁；

- 个人年收入：

  100000万；

- 籍贯：

  汉族。

#### 2.3 矛盾内容修正

有一些字段之间是可以互相验证的，要根据实际情况判断哪个更可靠，或者去除重构的不可靠的字段

### 3.0 异常值清洗

#### 3.1 异常值检测

1. 3σ原则
2. 箱线图分析
3. 基于模型的检测（不懂）
4. 基于距离
5. 基于密度
6. 基于聚类

#### 3.2 数据光滑处理

1）分箱

分箱方法通过考察数据的“近邻”（即周围的值）来光滑有序数据的值，有序值分布到一些“桶”或箱中。由于分箱方法考察近邻的值，因此进行局部光滑。

一般而言，宽度越大，光滑效果越明显。箱也可以是等宽的，其中每个箱值的区间范围是个常量。分箱也可以作为一种离散化技术使用。

##### 几种分箱光滑技术：

- 用箱均值光滑：

  箱中每一个值被箱中的平均值替换；

- 用箱中位数平滑：

  箱中的每一个值被箱中的中位数替换；

- 用箱边界平滑：

  箱中的最大和最小值同样被视为边界。

  箱中的每一个值被最近的边界值替换。

2）回归

可以用一个函数（如回归函数）拟合数据来光滑数据。

3）异常值处理方法

- 删除带有异常值的样本
- 将异常值视为缺失值，像缺失值一样处理
- 使用均值，中位数等进行修正
- 不处理



### 4.0 缺失值清洗 

#### 4.1 造成缺失值的原因

- 信息暂时无法获取
- 信息被遗漏
- 获取这些信息的成本太高
- 某些对象的某些属性是不可用的（儿童的固定收入）

#### 4.2 缺失值的处理方法

1）删除元组

直接删除缺失值所在的样本，对于缺失值样本量小的数据集适用，如果存在缺失值的样本是非随机分布的，并且占比较大，容易造成数据偏斜。

2）填充

3）不处理



##### 填充缺失值

1）使用统计量进行填充

##### 常用填充统计量：

- 平均值：

  对于数据符合均匀分布，用该变量的均值填补缺失值。

- 中位数：

  对于数据存在倾斜分布的情况，采用中位数填补缺失值。

- 众数：

  离散特征可使用众数进行填充缺失值。

2）条件平均值填充法（Conditional Mean Completer）：

在该方法中，用于求平均值/众数/中位数并不是从数据集的所有对象中取，而是从与该对象具有相同决策属性值的对象中取得。

```
# 条件平均值填充
def condition_mean_fillna(df, label_name, feature_name):
    mean_feature_name = '{}Mean'.format(feature_name)
    group_df = df.groupby(label_name).mean().reset_index().rename(columns={feature_name: mean_feature_name})

    df = pd.merge(df, group_df, on=label_name, how='left')
    df.loc[df[feature_name].isnull(), feature_name] = df.loc[df[feature_name].isnull(), mean_feature_name]
    df.drop(mean_feature_name, inplace=True, axis=1)
    return df

# df = condition_mode_fillna(df, 'Label', 'Feature2')
```

4）模型预测填充

建立分类，回归模型，对缺失值进行填充，将缺失值那一个位置看为label，如果这个位置为离散值，就是用分类器，如果这个位置为连续值，就使用回归器，去预测这个值。

##### 最近距离邻法（KNN）

先根据欧式距离或相关分析来确定距离具有缺失数据样本最近的K个样本，将这K个值加权平均/投票来估计该样本的缺失数据。

**回归**

当变量不是线性相关时会导致有偏差的估计。常用线性回归

##### 5）插值法填充

包括随机插值，多重插补法，热平台插补，拉格朗日插值，牛顿插值等。

##### 线性插值法

使用插值法可以计算缺失值的估计值，所谓的插值法就是通过两点（x0，y0），（x1，y1）估计中间点的值，假设y=f(x)是一条直线，通过已知的两点来计算函数f(x)，然后只要知道x就能求出y，以此方法来估计缺失值。

##### 多重插补（Multiple Imputation）

多值插补的思想来源于贝叶斯估计，认为待插补的值是随机的，它的值来自于已观测到的值。具体实践上通常是估计出待插补的值，然后再加上不同的噪声，形成多组可选插补值。根据某种选择依据，选取最合适的插补值。

多重插补方法分为三个步骤：

- Step1：

  为每个空值产生一套可能的插补值，这些值反映了无响应模型的不确定性；

  每个值都可以被用来插补数据集中的缺失值，产生若干个完整数据集合；

- Step2：

  每个插补数据集合都用针对完整数据集的统计方法进行统计分析；

- Step3：

  对来自各个插补数据集的结果，根据评分函数进行选择，产生最终的插补值。



6）哑变量填充

若变量是离散型，且不同值较少，可转换成哑变量，例如性别SEX变量，存在male，fameal，NA三个不同的值，可将该列转换成 `IS_SEX_MALE`、`IS_SEX_FEMALE`、`IS_SEX_NA`。若某个变量存在十几个不同的值，可根据每个值的频数，将频数较小的值归为一类’other’，降低维度。此做法可最大化保留变量的信息。



7）热卡填充（Hot deck imputation，就近补齐）	

热卡填充法在完整数据中找到一个与它最相似的对象，然后用这个相似对象的值来进行填充。不同的问题可能会选用不同的标准来对相似进行判定。该方法概念上很简单，且利用了数据间的关系来进行空值估计。

这个方法的缺点在于难以定义相似标准，主观因素较多。



8）期望值最大化填充（Expectation maximization，EM）

EM算法是一种在不完全数据情况下计算极大似然估计或者后验分布的迭代算法。在每一迭代循环过程中交替执行两个步骤：E步（Excepctaion  step，期望步），在给定完全数据和前一次迭代所得到的参数估计的情况下计算完全数据对应的对数似然函数的条件期望；M步（Maximzation  step，极大化步），用极大化对数似然函数以确定参数的值，并用于下步的迭代。算法在E步和M步之间不断迭代直至收敛，即两次迭代之间的参数变化小于一个预先给定的阈值时结束。该方法可能会陷入局部极值，收敛速度也不是很快，并且计算很复杂。

**缺点**：由线性模型化所报告的软件标准误和检验统计量并不正确，且对于过度识别模型，估计值不是全然有效的。



### 4.缺失值处理步骤

1）确定缺失值范围

对每个字段都计算其缺失值比例，然后按照缺失比例和字段重要性，分别制定策略，可用下图表示：

![img](https://mmbiz.qpic.cn/mmbiz_jpg/jA1wO8icw0gAr0N9oRvm5xELDAJZu1eJU1T4eFibiaNUY1KkC5icdsAgZfsdcwKsPrT6ecf00KKhC9VdDdWEKA9uHw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

2）去除不需要的字段

3）填充



### 5.非需求数据清洗

把不要的特征删了

在实际操作中，如果不知道哪些是非需求数据，可以不进行非需求数据清洗，在数据预处理之后再进行特征筛选