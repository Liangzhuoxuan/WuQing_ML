### 信息与熵

信息：$i(x)=-log(p(x))$，如果说概率是对**确定性**的度量，那么信息就是对**不确定性**的度量。

独立事件的信息：如果两个时间 X 和 Y 独立，$p(xy) = p(x)p(y)$，假定 X 和 Y 的信息量分别为 i(x) 和 i(y)，则两者同时发生的信息量为 $i(xy) = i(x) + i(y)$。

熵：熵是自信息的期望。

互信息：$i(y,x) = i(y) - i(y|x)  = i(x) - i(x|y)= log(p(y|x)/p(y))$

极大似然估计、最大熵算法 都属于**判别模型**

**判别模型**：在有限的可以观测的数据里面，观测数据，推断出最好状态下的参数，用这个参数去代表模型长什么样。也就是说，我知道模型的表达式，如 y=x^P^，特征 x~i~，是已知的，通过极大似然估计、最大熵等算法把 P 求出来，也就是说要知道什么 P 可以，使得模型最好的拟合数据。

**生成模型**：我们并不知道模型本身应该长什么样，我们要求的就是这个模型本身因该长什么样，通过无限的数据去不断拟合，最终得到一个最能描述数据本身的模型，EM算法就是其中一种。


EM算法 (期望最大化算法)：

